{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Quantum Computing"
      ],
      "metadata": {
        "id": "i51xya4V8uHd"
      },
      "id": "i51xya4V8uHd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a892fcc5",
      "metadata": {
        "id": "a892fcc5",
        "outputId": "813cc598-5a0b-47a5-d950-19890f77a391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          ┌─────────┐\n",
            "0: ───H───@────────────────×────────────\n",
            "          │                │\n",
            "1: ───H───X───@────────────┼────────────\n",
            "              │            │\n",
            "2: ───H───────X───@────────┼────────────\n",
            "                  │        │\n",
            "3: ───H───────────X───@────┼Rx(0.5π)────\n",
            "                      │    │\n",
            "4: ───H───────────────X────×────────────\n",
            "                          └─────────┘\n"
          ]
        }
      ],
      "source": [
        "import cirq\n",
        "import numpy as np\n",
        "\n",
        "# Define the circuit\n",
        "circuit = cirq.Circuit()\n",
        "\n",
        "# Define the qubits\n",
        "qubits = [cirq.LineQubit(i) for i in range(5)]\n",
        "\n",
        "# Add Hadamard gates to every qubit\n",
        "for qubit in qubits:\n",
        "    circuit.append(cirq.H(qubit))\n",
        "\n",
        "# Add CNOT gates to the specified pairs of qubits\n",
        "circuit.append(cirq.CNOT(qubits[0], qubits[1]))\n",
        "circuit.append(cirq.CNOT(qubits[1], qubits[2]))\n",
        "circuit.append(cirq.CNOT(qubits[2], qubits[3]))\n",
        "circuit.append(cirq.CNOT(qubits[3], qubits[4]))\n",
        "\n",
        "# Add SWAP gate between qubits 0 and 4\n",
        "circuit.append(cirq.SWAP(qubits[0], qubits[4]))\n",
        "\n",
        "# Add X rotation gate with pi/2 on qubit 3\n",
        "circuit.append(cirq.rx(0.5 * np.pi).on(qubits[3]))\n",
        "\n",
        "# Print the circuit\n",
        "print(circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd15eab",
      "metadata": {
        "id": "2cd15eab",
        "outputId": "7f63d92e-d71c-4755-dd82-8a405cbf9e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         ┌───┐     ┌───┐     ┌───┐┌─┐\n",
            "q_0: ────┤ H ├─────┤ H ├──■──┤ H ├┤M├\n",
            "     ┌───┴───┴────┐└───┘  │  └───┘└╥┘\n",
            "q_1: ┤ Rx(2.0944) ├──■────┼────────╫─\n",
            "     └───┬───┬────┘┌─┴─┐  │        ║ \n",
            "q_2: ────┤ H ├─────┤ X ├──┼────────╫─\n",
            "         ├───┤     └───┘┌─┴─┐      ║ \n",
            "q_3: ────┤ H ├──────────┤ X ├──────╫─\n",
            "         └───┘          └───┘      ║ \n",
            "c: 1/══════════════════════════════╩═\n",
            "                                   0 \n"
          ]
        }
      ],
      "source": [
        "from qiskit import QuantumCircuit, execute, Aer\n",
        "\n",
        "# Create a quantum circuit with 4 qubits\n",
        "circuit = QuantumCircuit(4, 1)\n",
        "\n",
        "# Apply Hadamard gate to the first qubit\n",
        "circuit.h(0)\n",
        "\n",
        "# Rotate the second qubit by pi/3 around X\n",
        "circuit.rx(2/3 * 3.14159, 1)\n",
        "\n",
        "# Apply Hadamard gate to the third and fourth qubit\n",
        "circuit.h(2)\n",
        "circuit.h(3)\n",
        "\n",
        "# Perform swap test between qubits 1 and 2, and qubits 3 and 4\n",
        "circuit.h(0)\n",
        "circuit.cx(0, 3)\n",
        "circuit.cx(1, 2)\n",
        "circuit.h(0)\n",
        "circuit.measure(0, 0)\n",
        "\n",
        "# Draw the circuit\n",
        "print(circuit.draw())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ba57c2",
      "metadata": {
        "id": "84ba57c2",
        "outputId": "e4e9f59c-c338-467b-c95d-571d385f3c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: energyflow in c:\\users\\user\\anaconda3\\lib\\site-packages (1.3.2)\n",
            "Requirement already satisfied: wasserstein>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from energyflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from energyflow) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from energyflow) (1.21.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from energyflow) (3.7.0)\n",
            "Requirement already satisfied: wurlitzer>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from wasserstein>=0.3.1->energyflow) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install energyflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a6493ec",
      "metadata": {
        "id": "7a6493ec"
      },
      "source": [
        "# Task 2 : Classical Graph Neural Network, Part 1:Using GCN's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e15357b",
      "metadata": {
        "id": "7e15357b"
      },
      "outputs": [],
      "source": [
        "import energyflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28cdf5d7",
      "metadata": {
        "id": "28cdf5d7"
      },
      "outputs": [],
      "source": [
        "dataset = energyflow.qg_jets.load(num_data=100000, pad=True, ncol=4, generator='pythia',with_bc=False, cache_dir='~/.energyflow')                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dab231",
      "metadata": {
        "id": "03dab231"
      },
      "outputs": [],
      "source": [
        "X = dataset[:-1][0]\n",
        "y = dataset[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6437e17",
      "metadata": {
        "id": "f6437e17"
      },
      "outputs": [],
      "source": [
        "sum_array_1 = []\n",
        "sum_array_2 = []\n",
        "sum_array_3 = []\n",
        "sum_array_4 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aea7127",
      "metadata": {
        "id": "9aea7127"
      },
      "outputs": [],
      "source": [
        "for i in range(X.shape[0]):\n",
        "    temp_1 = 0\n",
        "    temp_2 = 0\n",
        "    temp_3 = 0\n",
        "    temp_4 = 0\n",
        "    for j in range(X.shape[1]):\n",
        "        if(X[i][j][0]!=0):\n",
        "            temp_1 += X[i][j][0]\n",
        "        if(X[i][j][1]!=0):\n",
        "            temp_2 += X[i][j][1]\n",
        "        if(X[i][j][2]!=0):\n",
        "            temp_3 += X[i][j][2]\n",
        "        if(X[i][j][3]!=0):\n",
        "            temp_4 += X[i][j][3]\n",
        "    sum_array_1.append(temp_1)\n",
        "    sum_array_2.append(temp_2)\n",
        "    sum_array_3.append(temp_3)\n",
        "    sum_array_4.append(temp_4)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85fb63c1",
      "metadata": {
        "id": "85fb63c1"
      },
      "outputs": [],
      "source": [
        "mean_1 = sum(sum_array_1)/len(sum_array_1)\n",
        "mean_2 = sum(sum_array_2)/len(sum_array_2)\n",
        "mean_3 = sum(sum_array_3)/len(sum_array_3)\n",
        "mean_4 = sum(sum_array_4)/len(sum_array_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f7e452",
      "metadata": {
        "id": "24f7e452"
      },
      "outputs": [],
      "source": [
        "bool_1 = [i<=mean_1 for i in sum_array_1]\n",
        "bool_2 = [i<=mean_2 for i in sum_array_2]\n",
        "bool_3 = [i<=mean_3 for i in sum_array_3]\n",
        "bool_4 = [i<=mean_4 for i in sum_array_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77dd2dec",
      "metadata": {
        "id": "77dd2dec"
      },
      "outputs": [],
      "source": [
        "binary_1 = []\n",
        "for i in bool_1:\n",
        "    if(i==True):\n",
        "        binary_1.append(1)\n",
        "    else:\n",
        "        binary_1.append(0)\n",
        "binary_2 = []\n",
        "for i in bool_2:\n",
        "    if(i==True):\n",
        "        binary_2.append(1)\n",
        "    else:\n",
        "        binary_2.append(0)\n",
        "binary_3 = []\n",
        "for i in bool_3:\n",
        "    if(i==True):\n",
        "        binary_3.append(1)\n",
        "    else:\n",
        "        binary_3.append(0)\n",
        "binary_4 = []\n",
        "for i in bool_4:\n",
        "    if(i==True):\n",
        "        binary_4.append(1)\n",
        "    else:\n",
        "        binary_4.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc346896",
      "metadata": {
        "id": "bc346896"
      },
      "outputs": [],
      "source": [
        "binary = []\n",
        "for i in range(len(binary_1)):\n",
        "    binary.append(binary_1[i] + binary_2[i] + binary_3[i] + binary_4[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c5b125",
      "metadata": {
        "id": "d5c5b125"
      },
      "outputs": [],
      "source": [
        "connections_0 = []\n",
        "connections_1 = []\n",
        "connections_2 = []\n",
        "connections_3 = []\n",
        "connections_4 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2583c78d",
      "metadata": {
        "id": "2583c78d"
      },
      "outputs": [],
      "source": [
        "for i in range(len(binary)):\n",
        "    if(binary[i]==0):\n",
        "        connections_0.append(i)\n",
        "    if(binary[i]==1):\n",
        "        connections_1.append(i)\n",
        "    if(binary[i]==2):\n",
        "        connections_2.append(i)\n",
        "    if(binary[i]==3):\n",
        "        connections_3.append(i)\n",
        "    if(binary[i]==4):\n",
        "        connections_4.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7079e10",
      "metadata": {
        "id": "a7079e10"
      },
      "source": [
        "### The above lines of code is to basically make connections b/w nodes based on the mean values of the corresponding features.Note that this mean must be for each node (mean of the 37 datapoints including the paddings but the padded zeros are not considered while calculating the mean) , not the mean of every datapoint of all nodes.We create lists of indices whose features values are more than mean for 0 features,1 feature,2 features,3 features and 4(all) features respectively and these lists are connections_0,1,2,3 and 4.Else,it is considered a 1.It would have been way easier to use NumPy arrays for this,however,I have encountered a situation where I had to convert a list of lists having variable length to np arrays keeping their dimensions same and avoiding padding,which made it complicated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48058cfc",
      "metadata": {
        "id": "48058cfc",
        "outputId": "96055bac-2169-4f87-9281-614fc1a9a600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape:  (100000, 139, 4)\n"
          ]
        }
      ],
      "source": [
        "labels = []\n",
        "labels.append('Quarks')\n",
        "labels.append('Gluons')\n",
        "nodes = []\n",
        "N = X.shape[0]\n",
        "F = X.shape[2]\n",
        "print('X shape: ', X.shape)\n",
        "edge_list=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd12c52",
      "metadata": {
        "id": "7cd12c52"
      },
      "outputs": [],
      "source": [
        "edge_list=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8376be7",
      "metadata": {
        "id": "e8376be7"
      },
      "outputs": [],
      "source": [
        "for i in range(len(connections_1)-1):\n",
        "    edge_list.append((connections_1[i],connections_1[i+1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83b0a46",
      "metadata": {
        "id": "a83b0a46"
      },
      "outputs": [],
      "source": [
        "for i in range(len(connections_2)-1):\n",
        "    edge_list.append((connections_2[i],connections_2[i+1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea76af37",
      "metadata": {
        "id": "ea76af37"
      },
      "outputs": [],
      "source": [
        "for i in range(len(connections_3)-1):\n",
        "    edge_list.append((connections_3[i],connections_3[i+1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8397fa",
      "metadata": {
        "id": "1f8397fa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(connections_4)-1):\n",
        "    edge_list.append((connections_4[i],connections_4[i+1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6297b25d",
      "metadata": {
        "id": "6297b25d",
        "outputId": "969ba53b-8f0e-4f63-c90a-98cb6b087d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of nodes (N):  100000\n",
            "\n",
            "Number of features (F) of each node:  4\n",
            "\n",
            "Categories:  {'Gluons', 'Quarks'}\n",
            "\n",
            "Number of classes:  2\n"
          ]
        }
      ],
      "source": [
        "print('\\nNumber of nodes (N): ', N)\n",
        "print('\\nNumber of features (F) of each node: ', F)\n",
        "print('\\nCategories: ', set(labels))\n",
        "\n",
        "num_classes = len(set(labels))\n",
        "print('\\nNumber of classes: ', num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34f36e1",
      "metadata": {
        "id": "a34f36e1"
      },
      "outputs": [],
      "source": [
        "def limit_data(labels,limit=5000,val_num=0,test_num=5000):\n",
        "    '''\n",
        "    Get the index of train, validation, and test data\n",
        "    '''\n",
        "    label_counter = dict((l, 0) for l in labels)\n",
        "    train_idx = []\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        label = labels[i]\n",
        "        if label_counter[label]<limit:\n",
        "            #add the example to the training data\n",
        "            train_idx.append(i)\n",
        "            label_counter[label]+=1\n",
        "        \n",
        "        #exit the loop once we found 20 examples for each class\n",
        "        if all(count == limit for count in label_counter.values()):\n",
        "            break\n",
        "    \n",
        "    #get the indices that do not go to traning data\n",
        "    rest_idx = [x for x in range(len(labels)) if x not in train_idx]\n",
        "    val_idx = rest_idx[:val_num]\n",
        "    test_idx = rest_idx[val_num:(val_num+test_num)]\n",
        "    return train_idx, val_idx,test_idx\n",
        "\n",
        "train_idx,val_idx,test_idx = limit_data(labels)\n",
        "\n",
        "#set the mask\n",
        "train_mask = np.zeros((N,),dtype=bool)\n",
        "train_mask[train_idx] = True\n",
        "\n",
        "val_mask = np.zeros((N,),dtype=bool)\n",
        "val_mask[val_idx] = True\n",
        "\n",
        "test_mask = np.zeros((N,),dtype=bool)\n",
        "test_mask[test_idx] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4260fe24",
      "metadata": {
        "scrolled": true,
        "id": "4260fe24",
        "outputId": "4618995f-9ccf-4112-acce-55856e2da427"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3516\\631010150.py:8: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
            "  A = nx.adjacency_matrix(G)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph info:  Graph with 94576 nodes and 94572 edges\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3516\\631010150.py:9: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
            "\n",
            "  print('Graph info: ', nx.info(G))\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "#build the graph\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(nodes)\n",
        "G.add_edges_from(edge_list)\n",
        "\n",
        "#obtain the adjacency matrix (A)\n",
        "A = nx.adjacency_matrix(G)\n",
        "print('Graph info: ', nx.info(G))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff919f87",
      "metadata": {
        "id": "ff919f87",
        "outputId": "6c6c8f6e-c17e-43d9-a9c0-605fdcc3e019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04503a55",
      "metadata": {
        "id": "04503a55"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cb23e29",
      "metadata": {
        "id": "8cb23e29"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def encode_label(labels):\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "    labels = to_categorical(labels)\n",
        "    return labels, label_encoder.classes_\n",
        "\n",
        "labels_encoded, classes = encode_label(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6b50f9",
      "metadata": {
        "id": "3c6b50f9"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "channels = 16           # Number of channels in the first layer\n",
        "dropout = 0.5           # Dropout rate for the features\n",
        "l2_reg = 5e-4           # L2 regularization rate\n",
        "learning_rate = 1e-2    # Learning rate\n",
        "epochs = 200            # Number of training epochs\n",
        "es_patience = 10        # Patience for early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886b4145",
      "metadata": {
        "id": "886b4145"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import spektral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95722f8c",
      "metadata": {
        "id": "95722f8c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Renormalization trick: D^-1/2 * A * D^-1/2\n",
        "# Compute D^-1/2\n",
        "d = np.squeeze(np.asarray(sp.csr_matrix.sum(A, axis=1)))\n",
        "d_sqrt_inv = np.power(d, -0.5)\n",
        "d_sqrt_inv[np.isinf(d_sqrt_inv)] = 0.0\n",
        "D_sqrt_inv = sp.diags(d_sqrt_inv)\n",
        "\n",
        "# Compute D^-1/2 * A * D^-1/2\n",
        "A_norm = D_sqrt_inv.dot(A).dot(D_sqrt_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baefeb38",
      "metadata": {
        "id": "baefeb38"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c6a453",
      "metadata": {
        "id": "27c6a453",
        "outputId": "383a470b-5f94-4b23-e55a-a7e66066f39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.21.5)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.9.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2022.9.14)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea311e9",
      "metadata": {
        "id": "cea311e9",
        "outputId": "849d9371-6951-4cd2-cf11-2f0a9d863288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_sparse in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.16+pt113cpu)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_sparse) (1.9.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scipy->torch_sparse) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b036e3",
      "metadata": {
        "id": "d4b036e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a870c6d",
      "metadata": {
        "id": "1a870c6d"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "channels = 16           # Number of channels in the first layer\n",
        "dropout = 0.5           # Dropout rate for the features\n",
        "l2_reg = 5e-4           # L2 regularization rate\n",
        "learning_rate = 1e-2    # Learning rate\n",
        "epochs = 200            # Number of training epochs\n",
        "es_patience = 10        # Patience for early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70b55ccf",
      "metadata": {
        "scrolled": true,
        "id": "70b55ccf",
        "outputId": "ec7c7ccc-80d6-485e-e3c2-8687966fbf8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3516\\2390364636.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.float)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3516\\2390364636.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 104.2855\n",
            "Epoch 2, Loss: 54.2523\n",
            "Epoch 3, Loss: 23.1599\n",
            "Epoch 4, Loss: 2.3075\n",
            "Epoch 5, Loss: 0.6540\n",
            "Epoch 6, Loss: 0.6450\n",
            "Epoch 7, Loss: 0.6363\n",
            "Epoch 8, Loss: 0.6279\n",
            "Epoch 9, Loss: 0.6198\n",
            "Epoch 10, Loss: 0.6119\n",
            "Epoch 11, Loss: 0.6042\n",
            "Epoch 12, Loss: 0.5966\n",
            "Epoch 13, Loss: 0.5891\n",
            "Epoch 14, Loss: 0.5817\n",
            "Epoch 15, Loss: 0.5745\n",
            "Epoch 16, Loss: 0.5673\n",
            "Epoch 17, Loss: 0.5603\n",
            "Epoch 18, Loss: 0.5533\n",
            "Epoch 19, Loss: 0.5465\n",
            "Epoch 20, Loss: 0.5397\n",
            "Epoch 21, Loss: 0.5330\n",
            "Epoch 22, Loss: 0.5263\n",
            "Epoch 23, Loss: 0.5198\n",
            "Epoch 24, Loss: 0.5133\n",
            "Epoch 25, Loss: 0.5070\n",
            "Epoch 26, Loss: 0.5007\n",
            "Epoch 27, Loss: 0.4944\n",
            "Epoch 28, Loss: 0.4883\n",
            "Epoch 29, Loss: 0.4822\n",
            "Epoch 30, Loss: 0.4762\n",
            "Epoch 31, Loss: 0.4703\n",
            "Epoch 32, Loss: 0.4644\n",
            "Epoch 33, Loss: 0.4586\n",
            "Epoch 34, Loss: 0.4529\n",
            "Epoch 35, Loss: 0.4473\n",
            "Epoch 36, Loss: 0.4417\n",
            "Epoch 37, Loss: 0.4362\n",
            "Epoch 38, Loss: 0.4308\n",
            "Epoch 39, Loss: 0.4254\n",
            "Epoch 40, Loss: 0.4202\n",
            "Epoch 41, Loss: 0.4150\n",
            "Epoch 42, Loss: 0.4098\n",
            "Epoch 43, Loss: 0.4048\n",
            "Epoch 44, Loss: 0.3998\n",
            "Epoch 45, Loss: 0.3948\n",
            "Epoch 46, Loss: 0.3900\n",
            "Epoch 47, Loss: 0.3852\n",
            "Epoch 48, Loss: 0.3805\n",
            "Epoch 49, Loss: 0.3758\n",
            "Epoch 50, Loss: 0.3712\n",
            "Epoch 51, Loss: 0.3667\n",
            "Epoch 52, Loss: 0.3623\n",
            "Epoch 53, Loss: 0.3579\n",
            "Epoch 54, Loss: 0.3535\n",
            "Epoch 55, Loss: 0.3493\n",
            "Epoch 56, Loss: 0.3451\n",
            "Epoch 57, Loss: 0.3409\n",
            "Epoch 58, Loss: 0.3369\n",
            "Epoch 59, Loss: 0.3328\n",
            "Epoch 60, Loss: 0.3289\n",
            "Epoch 61, Loss: 0.3250\n",
            "Epoch 62, Loss: 0.3211\n",
            "Epoch 63, Loss: 0.3173\n",
            "Epoch 64, Loss: 0.3136\n",
            "Epoch 65, Loss: 0.3099\n",
            "Epoch 66, Loss: 0.3063\n",
            "Epoch 67, Loss: 0.3028\n",
            "Epoch 68, Loss: 0.2993\n",
            "Epoch 69, Loss: 0.2958\n",
            "Epoch 70, Loss: 0.2924\n",
            "Epoch 71, Loss: 0.2890\n",
            "Epoch 72, Loss: 0.2857\n",
            "Epoch 73, Loss: 0.2825\n",
            "Epoch 74, Loss: 0.2793\n",
            "Epoch 75, Loss: 0.2761\n",
            "Epoch 76, Loss: 0.2730\n",
            "Epoch 77, Loss: 0.2700\n",
            "Epoch 78, Loss: 0.2670\n",
            "Epoch 79, Loss: 0.2640\n",
            "Epoch 80, Loss: 0.2611\n",
            "Epoch 81, Loss: 0.2582\n",
            "Epoch 82, Loss: 0.2554\n",
            "Epoch 83, Loss: 0.2526\n",
            "Epoch 84, Loss: 0.2498\n",
            "Epoch 85, Loss: 0.2471\n",
            "Epoch 86, Loss: 0.2444\n",
            "Epoch 87, Loss: 0.2418\n",
            "Epoch 88, Loss: 0.2392\n",
            "Epoch 89, Loss: 0.2367\n",
            "Epoch 90, Loss: 0.2342\n",
            "Epoch 91, Loss: 0.2317\n",
            "Epoch 92, Loss: 0.2293\n",
            "Epoch 93, Loss: 0.2269\n",
            "Epoch 94, Loss: 0.2245\n",
            "Epoch 95, Loss: 0.2222\n",
            "Epoch 96, Loss: 0.2199\n",
            "Epoch 97, Loss: 0.2176\n",
            "Epoch 98, Loss: 0.2154\n",
            "Epoch 99, Loss: 0.2132\n",
            "Epoch 100, Loss: 0.2110\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Convert the renormalized adjacency matrix A to a sparse tensor format\n",
        "row, col = A.nonzero()\n",
        "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "\n",
        "# Convert X and y to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float)\n",
        "X_train = X.reshape(100000, 139*4)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Create a PyTorch Geometric data object\n",
        "data = Data(x=X_train, edge_index=edge_index,y=y)\n",
        "\n",
        "# Set the train and test masks as attributes of the data object\n",
        "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
        "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
        "\n",
        "# Initialize the GCN model\n",
        "model = GCN(num_features=139*4, hidden_channels=4, num_classes=2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cda0fa",
      "metadata": {
        "id": "53cda0fa"
      },
      "source": [
        "# The loss could further be improved by making connections more sophisticated.My original idea was to make these node connections based on a threshold on the deviation from mean rather than just a comparision of these features with their corresponding mean values,but the idea was scrapped due to limited computational power."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
