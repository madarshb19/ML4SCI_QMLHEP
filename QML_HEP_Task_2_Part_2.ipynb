{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5486e54",
      "metadata": {
        "id": "c5486e54"
      },
      "source": [
        "# Part 2:Graph Attention Network (GAT's)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f970a072",
      "metadata": {
        "id": "f970a072"
      },
      "source": [
        "## Other than the model architecture,the implementation is similiar to GCN's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530db3e7",
      "metadata": {
        "id": "530db3e7"
      },
      "outputs": [],
      "source": [
        "import energyflow\n",
        "dataset = energyflow.qg_jets.load(num_data=100000, pad=True, ncol=4, generator='pythia',with_bc=False, cache_dir='~/.energyflow') \n",
        "X = dataset[:-1][0]\n",
        "y = dataset[-1]\n",
        "sum_array_1 = []\n",
        "sum_array_2 = []\n",
        "sum_array_3 = []\n",
        "sum_array_4 = []\n",
        "for i in range(X.shape[0]):\n",
        "    temp_1 = 0\n",
        "    temp_2 = 0\n",
        "    temp_3 = 0\n",
        "    temp_4 = 0\n",
        "    for j in range(X.shape[1]):\n",
        "        if(X[i][j][0]!=0):\n",
        "            temp_1 += X[i][j][0]\n",
        "        if(X[i][j][1]!=0):\n",
        "            temp_2 += X[i][j][1]\n",
        "        if(X[i][j][2]!=0):\n",
        "            temp_3 += X[i][j][2]\n",
        "        if(X[i][j][3]!=0):\n",
        "            temp_4 += X[i][j][3]\n",
        "    sum_array_1.append(temp_1)\n",
        "    sum_array_2.append(temp_2)\n",
        "    sum_array_3.append(temp_3)\n",
        "    sum_array_4.append(temp_4)\n",
        "mean_1 = sum(sum_array_1)/len(sum_array_1)\n",
        "mean_2 = sum(sum_array_2)/len(sum_array_2)\n",
        "mean_3 = sum(sum_array_3)/len(sum_array_3)\n",
        "mean_4 = sum(sum_array_4)/len(sum_array_4)\n",
        "bool_1 = [i<=mean_1 for i in sum_array_1]\n",
        "bool_2 = [i<=mean_2 for i in sum_array_2]\n",
        "bool_3 = [i<=mean_3 for i in sum_array_3]\n",
        "bool_4 = [i<=mean_4 for i in sum_array_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a70ae2",
      "metadata": {
        "id": "82a70ae2"
      },
      "outputs": [],
      "source": [
        "binary_1 = []\n",
        "for i in bool_1:\n",
        "    if(i==True):\n",
        "        binary_1.append(1)\n",
        "    else:\n",
        "        binary_1.append(0)\n",
        "binary_2 = []\n",
        "for i in bool_2:\n",
        "    if(i==True):\n",
        "        binary_2.append(1)\n",
        "    else:\n",
        "        binary_2.append(0)\n",
        "binary_3 = []\n",
        "for i in bool_3:\n",
        "    if(i==True):\n",
        "        binary_3.append(1)\n",
        "    else:\n",
        "        binary_3.append(0)\n",
        "binary_4 = []\n",
        "for i in bool_4:\n",
        "    if(i==True):\n",
        "        binary_4.append(1)\n",
        "    else:\n",
        "        binary_4.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a318fcf2",
      "metadata": {
        "id": "a318fcf2"
      },
      "outputs": [],
      "source": [
        "binary = []\n",
        "for i in range(len(binary_1)):\n",
        "    binary.append(binary_1[i] + binary_2[i] + binary_3[i] + binary_4[i])\n",
        "connections_0 = []\n",
        "connections_1 = []\n",
        "connections_2 = []\n",
        "connections_3 = []\n",
        "connections_4 = []\n",
        "for i in range(len(binary)):\n",
        "    if(binary[i]==0):\n",
        "        connections_0.append(i)\n",
        "    if(binary[i]==1):\n",
        "        connections_1.append(i)\n",
        "    if(binary[i]==2):\n",
        "        connections_2.append(i)\n",
        "    if(binary[i]==3):\n",
        "        connections_3.append(i)\n",
        "    if(binary[i]==4):\n",
        "        connections_4.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967e8683",
      "metadata": {
        "id": "967e8683",
        "outputId": "36125b79-2105-49c4-fe0d-f7c2c252bc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape:  (100000, 139, 4)\n",
            "\n",
            "Number of nodes (N):  100000\n",
            "\n",
            "Number of features (F) of each node:  4\n",
            "\n",
            "Categories:  {'Gluons', 'Quarks'}\n",
            "\n",
            "Number of classes:  2\n"
          ]
        }
      ],
      "source": [
        "labels = []\n",
        "labels.append('Quarks')\n",
        "labels.append('Gluons')\n",
        "nodes = []\n",
        "N = X.shape[0]\n",
        "F = X.shape[2]\n",
        "print('X shape: ', X.shape)\n",
        "edge_list=[]\n",
        "for i in range(len(connections_1)-1):\n",
        "    edge_list.append((connections_1[i],connections_1[i+1]))\n",
        "for i in range(len(connections_2)-1):\n",
        "    edge_list.append((connections_2[i],connections_2[i+1]))\n",
        "for i in range(len(connections_3)-1):\n",
        "    edge_list.append((connections_3[i],connections_3[i+1]))\n",
        "for i in range(len(connections_4)-1):\n",
        "    edge_list.append((connections_4[i],connections_4[i+1]))\n",
        "print('\\nNumber of nodes (N): ', N)\n",
        "print('\\nNumber of features (F) of each node: ', F)\n",
        "print('\\nCategories: ', set(labels))\n",
        "\n",
        "num_classes = len(set(labels))\n",
        "print('\\nNumber of classes: ', num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20234c3",
      "metadata": {
        "id": "e20234c3",
        "outputId": "2a89e4ae-f04f-4a86-b273-47277a7c75f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7788\\631010150.py:8: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
            "  A = nx.adjacency_matrix(G)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph info:  Graph with 94576 nodes and 94572 edges\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7788\\631010150.py:9: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
            "\n",
            "  print('Graph info: ', nx.info(G))\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "#build the graph\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(nodes)\n",
        "G.add_edges_from(edge_list)\n",
        "\n",
        "#obtain the adjacency matrix (A)\n",
        "A = nx.adjacency_matrix(G)\n",
        "print('Graph info: ', nx.info(G))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df72bbc",
      "metadata": {
        "id": "3df72bbc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def limit_data(labels,limit=5000,val_num=0,test_num=5000):\n",
        "    '''\n",
        "    Get the index of train, validation, and test data\n",
        "    '''\n",
        "    label_counter = dict((l, 0) for l in labels)\n",
        "    train_idx = []\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        label = labels[i]\n",
        "        if label_counter[label]<limit:\n",
        "            #add the example to the training data\n",
        "            train_idx.append(i)\n",
        "            label_counter[label]+=1\n",
        "        \n",
        "        #exit the loop once we found 20 examples for each class\n",
        "        if all(count == limit for count in label_counter.values()):\n",
        "            break\n",
        "    \n",
        "    #get the indices that do not go to traning data\n",
        "    rest_idx = [x for x in range(len(labels)) if x not in train_idx]\n",
        "    val_idx = rest_idx[:val_num]\n",
        "    test_idx = rest_idx[val_num:(val_num+test_num)]\n",
        "    return train_idx, val_idx,test_idx\n",
        "\n",
        "train_idx,val_idx,test_idx = limit_data(labels)\n",
        "\n",
        "#set the mask\n",
        "train_mask = np.zeros((N,),dtype=bool)\n",
        "train_mask[train_idx] = True\n",
        "\n",
        "val_mask = np.zeros((N,),dtype=bool)\n",
        "val_mask[val_idx] = True\n",
        "\n",
        "test_mask = np.zeros((N,),dtype=bool)\n",
        "test_mask[test_idx] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08795c89",
      "metadata": {
        "id": "08795c89",
        "outputId": "f5307665-9f83-4f65-c13a-9aa8bd271307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.9.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_geometric) (1.21.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2022.9.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9040776",
      "metadata": {
        "id": "a9040776",
        "outputId": "bfd22c78-e6db-4008-fe15-7faf520d643e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.13.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd8826e",
      "metadata": {
        "id": "cbd8826e",
        "outputId": "982b57ae-fb6a-4d1b-e627-f832469e377e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_sparse in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.16+pt113cpu)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch_sparse) (1.9.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scipy->torch_sparse) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b122518e",
      "metadata": {
        "id": "b122518e",
        "outputId": "6d8f4b7f-2c36-48bb-fc43-31e6c8d428f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.13.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f902aa",
      "metadata": {
        "id": "d2f902aa"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf03268",
      "metadata": {
        "id": "dcf03268"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=2)\n",
        "        self.conv2 = GATConv(hidden_channels * 2, out_channels, heads=4)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c4feb6",
      "metadata": {
        "id": "15c4feb6"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "channels = 16           # Number of channels in the first layer\n",
        "dropout = 0.5           # Dropout rate for the features\n",
        "l2_reg = 5e-4           # L2 regularization rate\n",
        "learning_rate = 1e-2    # Learning rate\n",
        "epochs = 200            # Number of training epochs\n",
        "es_patience = 10        # Patience for early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4074c43a",
      "metadata": {
        "id": "4074c43a",
        "outputId": "feb7929a-c34b-44e6-de30-18a0980eda10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1460\\3708665358.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.float)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1460\\3708665358.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 884.0875\n",
            "Epoch 2, Loss: 55.2798\n",
            "Epoch 3, Loss: 601.2061\n",
            "Epoch 4, Loss: 397.2829\n",
            "Epoch 5, Loss: 0.0000\n",
            "Epoch 6, Loss: 251.6613\n",
            "Epoch 7, Loss: 0.0000\n",
            "Epoch 8, Loss: 26.9728\n",
            "Epoch 9, Loss: 0.0000\n",
            "Epoch 10, Loss: 0.0000\n",
            "Epoch 11, Loss: 0.0000\n",
            "Epoch 12, Loss: 0.0000\n",
            "Epoch 13, Loss: 0.0000\n",
            "Epoch 14, Loss: 0.0000\n",
            "Epoch 15, Loss: 0.0000\n",
            "Epoch 16, Loss: 0.0000\n",
            "Epoch 17, Loss: 0.0000\n",
            "Epoch 18, Loss: 0.0000\n",
            "Epoch 19, Loss: 0.0000\n",
            "Epoch 20, Loss: 0.0000\n",
            "Epoch 21, Loss: 0.0000\n",
            "Epoch 22, Loss: 0.0000\n",
            "Epoch 23, Loss: 0.0000\n",
            "Epoch 24, Loss: 29.4681\n",
            "Epoch 25, Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Convert the renormalized adjacency matrix A to a sparse tensor format\n",
        "row, col = A.nonzero()\n",
        "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "\n",
        "# Convert X and y to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float)\n",
        "X_train = X.reshape(100000, 139*4)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Create a PyTorch Geometric data object\n",
        "data = Data(x=X_train, edge_index=edge_index,y=y)\n",
        "\n",
        "# Set the train and test masks as attributes of the data object\n",
        "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
        "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
        "\n",
        "# Initialize the GCN model\n",
        "model = GAT(in_channels=139*4, hidden_channels=128, out_channels = 2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1e8181",
      "metadata": {
        "id": "8b1e8181"
      },
      "source": [
        "# I have tried multiple model architectures with different layers.However,unlike GCNs,the loss in the GAT model was not converging to a single value as the model was not being trained properly. I tried to increase the complexity of the model architecture to capture the essential relationships between these nodes,but the model seems to be overfitting.If the number of layers is low, it would be insufficient for message passing due to the extremely high number of nodes. Fine tuning the model and the model architecture by adding more dropout layers to prevent overfitting were also tried."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126acf82",
      "metadata": {
        "id": "126acf82"
      },
      "source": [
        "# In conclusion, GAT models were harder to fine tune due to the high number of parameters to prevent overfitting compared to GCNs and GCN model was found to be relatively more efficient although the contrary was expected as GATs are thought to be more effective for bigger datasets compared to GCNs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
